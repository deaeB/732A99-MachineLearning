---
title: "Untitled"
author: "Group 30"
date: "2022-11-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 3. Logistic regression and basis function expansion
The data file **pima-indians-diabetes.csv** contains information about the onset of
diabetes within 5 years in Pima Indians given medical details. The variables are (in
the same order as in the dataset):  
1. Number of times pregnant.  
2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test.  
3. Diastolic blood pressure (mm Hg).  
4. Triceps skinfold thickness (mm).  
5. 2-Hour serum insulin (mu U/ml).  
6. Body mass index (weight in kg/(height in m)^2).  
7. Diabetes pedigree function.  
8. Age (years).  
9. Diabetes (0=no or 1=yes)  

1.Make a scatterplot showing a Plasma glucose concentration on Age where
observations are colored by Diabetes levels. Do you think that Diabetes is easy
to classify by a standard logistic regression model that uses these two variables as
features? Motivate your answer.  


```{r 3.1, include=FALSE}
library(tidyverse)
library(ggplot2)

```
```{r 3.1}

data_PIdiabetes <- read.csv("D:/Program/Git/Repo/732A99-MachineLearning/lab01/Assignment3/pima-indians-diabetes.csv", col.names = c(1:9))

data_PIdiabetes$X9 <- factor(data_PIdiabetes$X9)

ggplot(data = data_PIdiabetes, aes(x = X8, y = X2, colour = X9)) + 
  geom_point() + 
  labs(x = "Age (years)", y = "Plasma glucose concentration", colour  = "Diabetes (0=no or 1=yes)" )

```

- Yes! Motivation: Looking at the plot, one can see that the plasma glucose concentration
is more higher for the group with Diabetes level 1 compared to those with level 0.
This is more evident when plasma glucose concentration is 150 or higher.
At such one can conclude that it will be easy
to classify Diabetes by a standard logistic regression

2.Train a logistic regression model with $y$ = Diabetes as target $x_1$ = Plasma glucose
concentration and $x_2$ = Age as features and make a prediction for all observations
by using $r$ = 0.5 as the classification threshold. Report the probabilistic equation
of the estimated model (i.e., how the target depends on the features and the
estimated model parameters probabilistically). Compute also the training
misclassification error and make a scatter plot of the same kind as in step 1 but
showing the predicted values of Diabetes as a color instead. Comment on the
quality of the classification by using these results

```{r 3.2 split, eval=FALSE, include=FALSE}
set.seed(24601)

n <- nrow(data_PIdiabetes)

r_train <- sample(1:n, floor(n*0.5))
train <-  data_PIdiabetes[r_train, ]

r_nont <- setdiff(1:n, r_train)
r_valid <- sample(r_nont, floor(n*0.25))
valid <- data_PIdiabetes[r_valid, ]
 
test <- data_PIdiabetes[setdiff(r_nont, r_valid), ]

```

```{r 3.2 glm}
# 2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test.
# 8. Age (years).
# 9. Diabetes (0=no or 1=yes).

glm_diabete <- glm(X9 ~ X2 + X8, data_PIdiabetes, family = binomial)

fit <- ifelse(fitted(glm_diabete) >= 0.5, 1, 0)

```

```{r 3.2 probabilistic equation}
glm_diabete$coefficients
```

- when r = 0.5, we have
$$\cfrac{1}{1 + e^{-\theta^T x}} = 0.5$$
then

```{r 3.2 misclassification&plot}

Misclass(fit, data_PIdiabetes$X9)

data_PIdiabetes_q1 <- data_PIdiabetes
data_PIdiabetes_q1$X10 <- factor(fit)

ggplot(data = data_PIdiabetes_q1, aes(x = X8, y = X2, colour = X10)) + 
  geom_point() + 
  labs(x = "Age (years)", y = "Plasma glucose concentration", colour = "Predicted Diabetes (0=no or 1=yes)" )


```

```{r 3.3}
theta <- coef(glm_diabete)

slope <- (-theta[3]) / theta[2]
intercept <- (-theta[1] ) / (theta[2]) 

ggplot(data = data_PIdiabetes_q1, aes(x = X8, y = X2, colour = X10)) + 
  geom_point() + 
  geom_abline(slope = slope, intercept = intercept) +
  
  labs(x = "Age (years)", y = "Plasma glucose concentration", colour  = "Predicted Diabetes (0=no or 1=yes)" )


```
```{r 3.4 r0.2}
fit_r02 <- ifelse(fitted(glm_diabete) >= 0.2, 1, 0)
Misclass(fit_r02, data_PIdiabetes$X9)

data_PIdiabetes_r02 <- data_PIdiabetes
data_PIdiabetes_r02$X10 <- factor(fit_r02)

slope <- (-theta[3]) / theta[2]
intercept <- (-log(4) - theta[1] ) / (theta[2]) 

ggplot(data = data_PIdiabetes_r02, aes(x = X8, y = X2, colour = X10)) + 
  geom_point() + 
  geom_abline(slope = slope, intercept = intercept) +
  
  labs(x = "Age (years)", y = "Plasma glucose concentration", colour  = "Predicted Diabetes (0=no or 1=yes)" )

```
```{r 3.4 r0.8}

fit_r08 <- ifelse(fitted(glm_diabete) >= 0.8, 1, 0)
Misclass(fit_r08, data_PIdiabetes$X9)

data_PIdiabetes_r08 <- data_PIdiabetes
data_PIdiabetes_r08$X10 <- factor(fit_r08)

slope <- (-theta[3]) / theta[2]
intercept <- (log(4) - theta[1] ) / (theta[2]) 

ggplot(data = data_PIdiabetes_r08, aes(x = X8, y = X2, colour = X10)) + 
  geom_point() + 
  geom_abline(slope = slope, intercept = intercept) +
  
  labs(x = "Age (years)", y = "Plasma glucose concentration", colour  = "Predicted Diabetes (0=no or 1=yes)" )


```

```{r 3.5}
data_PIdiabetes_q5 <-  data_PIdiabetes %>%  select(c(X2,X8,X9))
# X2,X8,X9
# 2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test.
# 8. Age (years).
# 9. Diabetes (0=no or 1=yes).

data_PIdiabetes_q5$Z1 <- data_PIdiabetes_q5$X2^4
data_PIdiabetes_q5$Z2 <- data_PIdiabetes_q5$X2^3 * data_PIdiabetes_q5$X8^1
data_PIdiabetes_q5$Z3 <- data_PIdiabetes_q5$X2^2 * data_PIdiabetes_q5$X8^2
data_PIdiabetes_q5$Z4 <- data_PIdiabetes_q5$X2^1 * data_PIdiabetes_q5$X8^3
data_PIdiabetes_q5$Z5 <- data_PIdiabetes_q5$X8^3

glm_diabete_q5 <- glm(X9 ~ X2 + X8 + Z1 + Z2 + Z3 + Z4 + Z5, data_PIdiabetes_q5, family = binomial)

fit <- ifelse(fitted(glm_diabete) >= 0.5, 1, 0)

Misclass(fit, data_PIdiabetes_q5$X9)

data_PIdiabetes_q5$X10 <- factor(fit)

ggplot(data = data_PIdiabetes_q5, aes(x = X8, y = X2, colour = X10)) +
  geom_point() +
  labs(x = "Age", y = "Plasma glucose concentration", colour  = "Predicted Diabetes (0=no or 1=yes)")

```


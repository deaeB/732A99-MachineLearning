---
title: "Lab01 Assignment2"

output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Question 1
**Divide it into training and test data (60/40) and scale it appropriately. In the coming steps, assume that motor_UPDRS is normally distributed and is a function of the voice characteristics, and since the data are scaled, no intercept is needed in the modelling.**

The code is given in Appendix.

## Question 2
**Compute a linear regression model from the training data, estimate training and test MSE and comment on which variables contribute significantly to the model.**

Training MSE is 0.87854
Test MSE is 0.93945

When we use summary function we can find that some P values of parameters are marked with three stars. That means these parameters contribute most to the result. They are shown in the picture in Appendix.They are respectively Jitter.Abs Shimmer.APQ5 Shimmer.APQ11 NHR HNR DFA PPE


## Question 3
**Implementing 4 functions, which are "Loglikelihood function", " Ridge function", "RidgeOpt function", "DF function".**

Four functions are given in Appendix.

We create the "Loglikelihood function" based on the following formula:
$\ln p(\mathbf y|\mathbf X;\mathbf \theta) = -\frac{n}{2} \ln(2\pi\sigma^2_\epsilon) - \frac{1}{2\sigma^2_\epsilon}\sum_{i =1}^n(\theta^\mathrm T \mathbf x_i -y_i)^2$


If we want to create "Ridge function", we need to add $\lambda ||\theta||_2^2$ to the last formula.



## Question 4

**By using function RidgeOpt, compute optimal** $\theta$ **parameters for** $\lambda$**= 1,** $\lambda$ **= 100 and** $\lambda$ **= 1000. Use the estimated parameters to predict the motor_UPDRS values for training and test data and report the training and test MSE values. Which penalty parameter is most appropriate among the selected ones? Compute and compare the degrees of freedom of these models and make appropriate conclusions.**

|$\lambda$|$Training\_MSE$|$Test\_MSE$|$DF$|
|:----:|:----:|:----:|:----:|
|1|0.8786|0.9350|14.86|
|100|0.8844|0.9323|10.90|
|1000|0.9211|0.9539|6.42|


By comparison we found that as the value of the $\lambda$ increases, the value of DF decreases. At the same time, in general the predicted results would be less and less accurate. We also noticed that the optimum  $\lambda$ is 100, which means in order to get the relatively less errors, we should not use the extreme values of $\lambda$.



## Appendix
```{r include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(lattice)
library(caret)
```


```{r}
my_data = read.csv("parkinsons.csv")
set.seed(12345)
n = nrow(my_data)
id = sample(1:n, floor(n*0.6))
train = my_data[id,]
test = my_data[-id,]


scaler = preProcess(train)
trainS = predict(scaler, train)
testS = predict(scaler, test)


# train MSE
trainS_1 = trainS %>% select(motor_UPDRS, 7:22)# what should we do if name of one column contains #
ml = lm(motor_UPDRS~.,trainS_1)
summary(ml)
Preds = predict(ml)
MSE_training = mean((trainS_1$motor_UPDRS - Preds)^2)

# test MSE
testS_1 = testS %>% select(motor_UPDRS, 7:22)
Preds_2 = predict(ml,testS_1)


MSE_test = mean((testS_1$motor_UPDRS - Preds_2)^2)



# The third question.

#a
n <- nrow(trainS)
trainS_1 <- tibble(trainS_1)
one <- tibble(one = rep(1,n))

trainS_1_new <- trainS_1%>%
  select(-motor_UPDRS)%>%
  mutate(one, .)


likelihood <- function(xita,sigma){
  n <- nrow(trainS)
  y_hat <- difference <- as.matrix(trainS_1_new) %*% as.matrix(xita)
  difference <- trainS_1$motor_UPDRS - y_hat
  square_difference <- difference^2
  sum <- sum(square_difference)
  return((-n/2) * log(2 * pi * sigma^2 ) - (1 / (2 * sigma^2)) * sum)

}

#b
Ridge <- function(lambda, xita, sigma){
  -likelihood(xita,sigma) + lambda * sum(xita^2)
}


#c
RidgeOpt <- function(lambda){

  to_optimize <- function(x){
    x1 = x[1:17]
    x2 = x[18]
    return(Ridge(lambda, x1, x2))
  }
  optim(rep(1, times = 18), fn = to_optimize, method = "BFGS")
}



#d
DF <- function(lambda){
  X <- as.matrix(trainS_1_new)
  I <- diag(ncol(trainS_1))
  element_I <- diag(X %*% solve((t(X) %*% X + lambda * I)) %*% t(X))
  df <- sum(element_I)
  return(df)
}
df_1 <- DF(1)
df_100 <- DF(100)
df_1000 <- DF(1000)

#e

#when lambda equals 1, theta
theta_sigma_1 <- RidgeOpt(1)
theta_1 <- theta_sigma_1$par[1:17]

##MSE for training data
y_hat_tr_1 <- as.matrix(trainS_1_new) %*% as.matrix(theta_1)
MSE_train_1 <-mean((y_hat_tr_1 - trainS_1$motor_UPDRS)^2)

##MSE for test data
n_2 <- nrow(testS)
testS_1 <- tibble(testS_1)
one_2 <- tibble(one = rep(1,n_2))

testS_1_new <- testS_1%>%
  select(-motor_UPDRS)%>%
  mutate(one_2, .)

y_hat_test_1 <- as.matrix(testS_1_new) %*% as.matrix(theta_1)
MSE_test_1 <- mean((y_hat_test_1 - testS_1$motor_UPDRS)^2)





#when lambda equals 100, theta
theta_sigma_2 <- RidgeOpt(100)
theta_2 <- theta_sigma_2$par[1:17]


## MSE for training data

y_hat_tr_2 <- as.matrix(trainS_1_new) %*% as.matrix(theta_2)
MSE_train_2 <-mean((y_hat_tr_2 - trainS_1$motor_UPDRS)^2)

## MSE for test data
y_hat_test_2 <- as.matrix(testS_1_new) %*% as.matrix(theta_2)
MSE_test_2 <- mean((y_hat_test_2 - testS_1$motor_UPDRS)^2)




#when lambda equals 1000, theta
theta_sigma_3 <- RidgeOpt(1000)
theta_3 <- theta_sigma_3$par[1:17]

## MSE for training data

y_hat_tr_3 <- as.matrix(trainS_1_new) %*% as.matrix(theta_3)
MSE_train_3 <-mean((y_hat_tr_3 - trainS_1$motor_UPDRS)^2)

## MSE for test data
y_hat_test_3 <- as.matrix(testS_1_new) %*% as.matrix(theta_3)
MSE_test_3 <- mean((y_hat_test_3 - testS_1$motor_UPDRS)^2)

```








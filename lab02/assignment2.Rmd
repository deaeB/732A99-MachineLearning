---
title: "Untitled"
author: "Jin Yan"
date: "2022-12-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## task1
```{r}
mydata <- read.csv("bank-full.csv", sep = ";",stringsAsFactors = TRUE)
mydata <- mydata[,-6]
n <- dim(mydata)[1]
set.seed(12345)
id_1 <- sample(1:n,floor(n * 0.4))

id_rest <- setdiff(1:n,id_1)
set.seed(12345)
id_2 <- sample(id_rest, floor(0.5 * length(id_rest)))

id_3 <- setdiff(id_rest,id_2)

data_train <- mydata[id_1,]
data_validation <- mydata[id_2,]
data_test <- mydata[id_3,]
```



## task2
In terms of the misclassification rates, the third tree is the best.When we make
the deviance smaller, the tree will become bigger.This is only is this way,can 
the tree satisfy this criterion. If we increase the node size, this 
classification will continue for smaller steps because this will make the 
observations contained in each nodes more.

```{r}
# the first decision tree without any limitation
library(tree)
tree_first <- tree(y~.,data = data_train)

predict_train_1 <- predict(tree_first, newdata = data_train,type = "class")
mis_train_1 <- mean(data_train[,16]!= predict_train_1)

predict_valid_1 <- predict(tree_first, newdata = data_validation,type = "class")
mis_valid_1 <- mean(data_validation[,16]!= predict_valid_1)
mis_valid_1
# the second decision tree with smallest allowed node size equal to 7000.

tree_second <- tree(y~.,data = data_train,control = tree.control(18084,minsize = 7000))

predict_train_2 <- predict(tree_second, newdata = data_train,type = "class")
mis_train_2 <- mean(data_train[,16]!= predict_train_2)

predict_valid_2 <- predict(tree_second, newdata = data_validation,type = "class")
mis_valid_2 <- mean(data_validation[,16]!= predict_valid_2)
mis_valid_2
# the third decision tree(minimum deviance to 0.0005)

tree_third <- tree(y~.,data = data_train,control = tree.control(18084,mindev = 0.0005))

predict_train_3 <- predict(tree_third, newdata = data_train,type = "class")
mis_train_3 <- mean(data_train[,16]!= predict_train_3)

predict_valid_3 <- predict(tree_third, newdata = data_validation,type = "class")
mis_valid_3 <- mean(data_validation[,16]!= predict_valid_3)
mis_valid_3
```

## task3
"duration" "poutcome" "month" "day" "contact" "age" "pdays" "previous" "housing"
are variables used in tree construction.

the best number of leaves are 43.
```{r}
map <- data.frame(leave_numbers = rep(0,49), train_de = rep(0,49), valid_de = rep(0,49))

i <- 1
while(i < 50){
  tree_pruned <- prune.tree(tree_third,best = i + 1)
  predict_train_new <- predict(tree_pruned, type = "tree",newdata = data_train)
  predict_valid_new <- predict(tree_pruned, type = "tree", newdata = data_validation)
  map[i,] <- c(i + 1, deviance(predict_train_new),deviance(predict_valid_new))
  i <- i + 1
}

# the best number of leaves are 43.
index <- order(map$valid_de)[1]
leave_number <- map$leave_numbers[index]
leave_number

# plot
library(reshape2)
melt_map <- melt(map, id.vars = "leave_numbers")

library(ggplot2)
ggplot(data = melt_map, aes(x = leave_numbers, y = value, color = variable)) +
  geom_line() + geom_point() + xlab("leave numbers") + ylab("deviance")

optimal_tree <- prune.tree(tree_third,best = leave_number)
summary(optimal_tree)

```

## task4
In terms of accuracy, this model actually has a strong predicting power. Compare
"accuracy" and "F1 score" we find using F1 sore can tell use more detailed information.
This would be helpful for our analyzing.
```{r}
predict_test <- predict(optimal_tree,newdata = data_test, type = "class")
confusion_matrix <- table(data_test[,16],predict_test)
confusion_matrix


true_positive <- confusion_matrix[2,2]
false_negative <- confusion_matrix[2,1]
false_positive <- confusion_matrix[1,2]
recall <- true_positive / (true_positive + false_negative)
precision <- true_positive / (true_positive + false_positive)
F1 <- 2 * precision * recall / (precision + recall)
F1 
accuracy <- 1 - mean(data_test[,16] != predict_test)
accuracy
```

## task5
Compared to the the results in the fourth question, I found that the accuracy
F1 value increased. This is because the the usage of loss matrix increase "true_positive" rate.
```{r}
loss_matrix <- matrix(c(0,5,1,0), nrow = 2, ncol = 2, byrow = T)

new_tree <- prune.tree(tree_third, best = leave_number, loss = loss_matrix)
predict_test_2 <- predict(new_tree, type = "class", newdata = data_test)

confusion_matrix2 <- table(data_test[,16],predict_test_2)
confusion_matrix2

true_positive2 <- confusion_matrix2[2,2]
false_negative2 <- confusion_matrix2[2,1]
false_positive2 <- confusion_matrix2[1,2]
recall2 <- true_positive2 / (true_positive2 + false_negative2)
precision2 <- true_positive2 / (true_positive2 + false_positive2)
F1_2 <- 2 * precision2 * recall2 / (precision2 + recall2)
F1_2

accuracy_2 <- 1 - mean(data_test[,16] != predict_test_2)
accuracy_2
```

